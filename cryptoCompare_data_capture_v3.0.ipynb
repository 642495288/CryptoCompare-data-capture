{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert unix time stmap\n",
    "def convert_time(ts):\n",
    "    time = datetime.datetime.fromtimestamp(ts)\n",
    "    return str(time)\n",
    "#=(C2+8*3600)/86400+70*365+19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values\n",
    "def drop_empty(dataframe):\n",
    "    for i in range(0,len(dataframe)):\n",
    "        if dataframe.loc[i,'close'] == 0:\n",
    "            dataframe = dataframe.drop([i])\n",
    "        else:\n",
    "            break\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiting status display\n",
    "def wait(sleepTime):\n",
    "    print(\"Waiting...restart after:\")\n",
    "    for i in range(0, sleepTime):\n",
    "        print(\"    \" + str(sleepTime) +\" second(s)\")\n",
    "        time.sleep(1)\n",
    "        sleepTime -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get price data via connecting API\n",
    "def get_price_data(apiKey, url_data, exchange, fsym, tsym, limit, current_time, rounds):\n",
    "    price_data = pd.DataFrame(columns=('time', 'close','high','low','open','volumefrom','volumeto'))\n",
    "    print(\"Estimated finsh time: \" + str(rounds * 3) + \"(s)\")\n",
    "    duration = 0\n",
    "    st = time.perf_counter()\n",
    "    for i in range(0,rounds):\n",
    "        payload_data = { \"api_key\": apiKey, \"e\" : exchange, \"fsym\": fsym, \"tsym\": tsym, \"limit\": limit, \"toTs\": current_time}\n",
    "        duration = round(time.perf_counter() - st, 2)\n",
    "        while(True):\n",
    "            try: \n",
    "                print(\"Getting data processing in: \" + str(i + 1) + '/' + str(rounds), end=\"\\r\")\n",
    "                response = requests.get(url_data, params=payload_data, timeout=20)\n",
    "                response.raise_for_status()\n",
    "                result = response.json()\n",
    "                df = pd.DataFrame(result['Data'])\n",
    "                price_data = df.append(price_data, sort=True)\n",
    "                current_time = df.head(1).time.values[0] + 60\n",
    "                break\n",
    "            except Exception:\n",
    "                print(\"Connection refused by the server..\")\n",
    "                wait(5)\n",
    "                print(\"Continue...\")\n",
    "                continue\n",
    "        \n",
    "#  end_ts = price_data.tail(1).time.values[0]\n",
    "    #   #####\n",
    "    price_data_reindex = price_data.reset_index()\n",
    "    price_data_dropnull = drop_empty(price_data_reindex)\n",
    "    print(\"\\n \")\n",
    "    print(\"Actual finsh time: \" + str(duration) + \"(s)\")\n",
    "    print(\"\\n \")\n",
    "    print(\"Capturing completed!\")\n",
    "    return price_data_dropnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pair information via connecting API\n",
    "def get_histo_data(apiKey, exchange, fsym, tsym, last_file, current_time, all_files_loc):\n",
    "\n",
    "    # Config data volumn parm\n",
    "    payload_volumn = {\n",
    "        \"api_key\": apiKey,\n",
    "        \"e\" : exchange\n",
    "        }\n",
    "\n",
    "    # Get data total volumn\n",
    "    # Use /exchanges to get exchanges data\n",
    "    url_vol = \"https://min-api.cryptocompare.com/data/v4/all/exchanges\"\n",
    "    \n",
    "    # Url to connect with API\n",
    "    url_data = \"https://min-api.cryptocompare.com/data/histohour\"\n",
    "\n",
    "    # Request data\n",
    "    while(True):\n",
    "        try:\n",
    "            # Send Request\n",
    "            result_volumn = requests.get(url_vol, params=payload_volumn, timeout=20).json()\n",
    "            break\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            wait(5)\n",
    "            print(\"Continue...\")\n",
    "            continue\n",
    "    # Get start and end timestamp\n",
    "    try:\n",
    "        pair_start_at = result_volumn['Data']['exchanges'][exchange]['pairs'][fsym]['tsyms'][tsym]['histo_minute_start_ts']\n",
    "        #pair_end_at = result_volumn['Data']['exchanges'][exchange]['pairs'][fsym]['tsyms'][tsym]['histo_minute_end_ts']\n",
    "        pair_end_at = current_time\n",
    "    except BaseException:\n",
    "        # If any of parameters is wrong, terminated process\n",
    "        print(\"Parameter Error! process terminated...\")\n",
    "        return\n",
    "\n",
    "    # Calculate data volumn & rounds of the loop based on last file\n",
    "    rounds = 1\n",
    "    limit = 2000\n",
    "    print(\"Start capturing data: \"+ fsym + \" to \"+ tsym + \" in \" + exchange)\n",
    "    try:\n",
    "        # Try to open the previous data file\n",
    "        pre_data = pd.read_csv(last_file)\n",
    "        # If last file is existed\n",
    "        print(last_file + \" Found. \")\n",
    "        print(\"Continue capture data...\")\n",
    "        print(\"----------------------------------------------\" )\n",
    "        pair_start_at = pre_data.tail(1).time.values[0]\n",
    "        print(\"Last data end at:  \" + convert_time(pair_start_at))\n",
    "        print(\"Start capture at:   \" + convert_time(current_time))\n",
    "        # Calculate total volumn of the pair\n",
    "        data_total_volumn = int(round((current_time - pair_start_at) / 3600))\n",
    "        if data_total_volumn >= 2000:\n",
    "            rounds = round(data_total_volumn / 2000)\n",
    "        else:\n",
    "            limit = data_total_volumn\n",
    "        print(\"Need to be added:  \" + str(data_total_volumn) + \" record(s)\")\n",
    "        # Get price data\n",
    "        print(\"----------------------------------------------\" )\n",
    "        if data_total_volumn == 0:\n",
    "            print(\"No data to update\")\n",
    "            print(\"Terminated...\")\n",
    "        else:\n",
    "            print(\"loading...\")\n",
    "            data_update = get_price_data(apiKey, url_data,exchange, fsym, tsym, limit, current_time, rounds).drop(index=[0])\n",
    "            # Append to previous data file\n",
    "            new_data = pre_data.append(data_update, sort=True)\n",
    "            # Generate the standard file name\n",
    "            file_name = all_files_loc + \"/\" + exchange + \"_hourly_\" + fsym + \"_\" + tsym + \"_\" + str(current_time) + \".csv\" \n",
    "            print(file_name)\n",
    "            new_data.to_csv(file_name)\n",
    "            print(\"Successfully saved as file: \" + str(file_name))\n",
    "    except FileNotFoundError:\n",
    "        # If the previous file is not found\n",
    "        if len(all_files_loc) == 0:\n",
    "            # If there is no previous file\n",
    "            print(\"History file Not Found.\")\n",
    "        else:\n",
    "            # If previous file is not existed\n",
    "            print(last_file + \" Not Found.\")\n",
    "        print(\"Create new file...\")\n",
    "        print(\"----------------------------------------------\" )\n",
    "        print(\"History data start at:  \" + convert_time(pair_start_at))\n",
    "        print(\"Start capture at:        \" + convert_time(current_time))\n",
    "         # Total volumn of the pair\n",
    "        data_total_volumn = int(round((current_time - pair_start_at) / 3600))\n",
    "        if data_total_volumn >= 2000:\n",
    "            rounds = round(data_total_volumn / 2000)\n",
    "        else:\n",
    "            limit = data_total_volumn\n",
    "        print(\"Total data volumn:      \" + str(data_total_volumn))\n",
    "        print(\"----------------------------------------------\" )\n",
    "        print(\"loading...\")\n",
    "        # Get price data\n",
    "        new_data = get_price_data(apiKey, url_data,exchange, fsym, tsym, limit, current_time, rounds)\n",
    "        # Generate the standard file name\n",
    "        file_name = all_files_loc + \"/\" + exchange + \"_hourly_\" + fsym + \"_\" + tsym + \"_\" + str(current_time) + \".csv\" \n",
    "        new_data.to_csv(file_name)\n",
    "        print(\"Successfully saved as file: \" + str(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the objective exchange(s) info\n",
    "# You must get the exchange data first\n",
    "def load_exchange_address_book(file_name):\n",
    "    return pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file list\n",
    "def load_exist_file(filePath):\n",
    "    return os.listdir(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if file is exist\n",
    "# return the file name\n",
    "def is_file_exits(file_name, all_files):\n",
    "    return file_name in all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get multiple pairs\n",
    "def get_multi_pairs(apiKey, exchanges, all_files, current_time, last_end_time, all_files_loc, history_file):\n",
    "    for i in range(0, len(exchanges)):\n",
    "        # Get exchange and pair info\n",
    "        exchange_name = exchanges.loc[i, 'exchange']\n",
    "        fsym = exchanges.loc[i, 'fsym']\n",
    "        tsym = exchanges.loc[i, 'tsym']\n",
    "        # Generate standard data file name\n",
    "        file_name =  exchange_name + \"_hourly_\" + fsym + \"_\" + tsym + \"_\" + str(current_time) + \".csv\"\n",
    "        last_file_name = exchange_name + \"_hourly_\" + fsym + \"_\" + tsym + \"_\" + str(last_end_time) + \".csv\"\n",
    "        if is_file_exits(file_name, all_files):\n",
    "            print(file_name + \" is existed jump over\")\n",
    "            continue\n",
    "        else:\n",
    "            print(\" \")      \n",
    "            last_file = history_file + '/'+ last_file_name\n",
    "            get_histo_data(apiKey, exchange_name, fsym, tsym, last_file, current_time, all_files_loc)\n",
    "            print(\" \")\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record last end time\n",
    "def write_last_end_time(loction, ts):\n",
    "    f = open(loction, 'w')\n",
    "    f.write(str(ts))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read last end time\n",
    "def read_lats_end_time(loction):\n",
    "    return int(open(loction).readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main function1\n",
    "# # Get one specific crypto pair history data\n",
    "\n",
    "# #=====================(Param Sample)=========================\n",
    "# # Use your api key   \n",
    "# apiKey = \"xxxxxxxxxxxxxx\"\n",
    "\n",
    "# # Exchange name:  \n",
    "\n",
    "# exchange = \"BitTrex\"  \n",
    "\n",
    "# # Pair \n",
    "\n",
    "# fsym = \"ETH\"        \n",
    "# tsym = \"USDT\"   \n",
    "\n",
    "# # Current unix time\n",
    "# end = int(time.time())\n",
    "\n",
    "# #==========================================================\n",
    "\n",
    "# #========================(Optional)============================\n",
    "# # Last file \n",
    "# # The data file captured last time, \n",
    "# # If you want to continue capture data, \n",
    "# # Please fill in the last_file with previous file name\n",
    "# # Otherwise 'last_file' set with empty String as default\n",
    "\n",
    "# last_file = \"\"\n",
    "# #==========================================================\n",
    "# Please create one before store the data\n",
    "# all_files_loc = 'D:/Data'\n",
    "# get_histo_data(apiKey, exchange, fsym, tsym, last_file, end, all_files_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_ts():\n",
    "    unit = 3600\n",
    "    cur_time = int(time.time())\n",
    "    return cur_time - ( cur_time % unit )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_to_time(ts):\n",
    "    real_time = time.localtime(ts)\n",
    "    return  time.strftime(\"%Y-%m-%d %H:%M:%S\", real_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_last_cap_time(loc, current_ts):\n",
    "    if not os.path.exists(loc):\n",
    "        print(\"Data history capture time file not found, creating new at: \" + loc)\n",
    "        print(\"Creating new history file...\")\n",
    "        time.sleep(2)\n",
    "        create_last_cap_time(loc, current_ts)\n",
    "        print(\"Location: \" + loc +\" is created\" + '\\n')\n",
    "        print(\"Now capture start at: \" + str(ts_to_time(current_ts)) + '\\n')\n",
    "        return current_ts\n",
    "    else:\n",
    "        print(\"Data history capture file: \" + loc + '\\n')\n",
    "        last_capture_time = read_last_cap_ts(loc)\n",
    "        print(\"Last capture start at: \" + str(ts_to_time(int(last_capture_time))))\n",
    "        print(\"Now capture start at: \" + str(ts_to_time(current_ts)))\n",
    "        print(\"----------------------------------------------------\" + '\\n')\n",
    "        write_last_cap_time(loc, current_ts)\n",
    "        return last_capture_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_last_cap_time(loc, current_ts):\n",
    "    file_loc = loc.split('/')[0] + loc.split('/')[1] \n",
    "    os.mkdir(file_loc)\n",
    "    f = open(loc, 'w+')\n",
    "    f.write(str(current_ts) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_last_cap_time(loc, current_ts):\n",
    "    f = open(loc, 'a')\n",
    "    f.write(str(current_ts) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_storage_file(all_files_loc):\n",
    "    if not os.path.exists(all_files_loc):\n",
    "        print(\"Data storage file not found, creating new at: \" + all_files_loc)\n",
    "        print(\"Creating new file dictionary...\")\n",
    "        time.sleep(2)\n",
    "        os.mkdir(all_files_loc)\n",
    "        print(\"Location: \" + all_files_loc +\" is created  \\n\")\n",
    "    else:\n",
    "        print(\"Data store location: \" + all_files_loc + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histroy_data_file(loc):\n",
    "    if not os.path.exists(loc):\n",
    "        print(\"Data history file not found, creating new at: \" + loc)\n",
    "        print(\"Creating new file dictionary...\")\n",
    "        time.sleep(2)\n",
    "        os.mkdir(loc)\n",
    "        print(\"Location: \" + loc +\" is created  \\n\")\n",
    "    else:\n",
    "        print(\"History data store location: \" + loc + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_last_cap_ts(loc):\n",
    "    f = open(hist_cap_time_loc)\n",
    "    contents = f.readlines()\n",
    "    last_ts = contents[len(contents) - 1].replace('\\n', '')\n",
    "    f.close()\n",
    "    return last_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_history_file(all_history_files, all_files_loc, histroy_files_loc):\n",
    "    if len(all_history_files) != 0:\n",
    "        for i in range(0, len(all_history_files)):\n",
    "            origin_loc = all_files_loc + '/' + all_history_files[i]\n",
    "            his_loc = histroy_files_loc + '/' + all_history_files[i]\n",
    "            shutil.move(origin_loc, his_loc)\n",
    "            print(\"Moving file: \")\n",
    "            print(origin_loc)\n",
    "            print('to: ')\n",
    "            print(his_loc + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}